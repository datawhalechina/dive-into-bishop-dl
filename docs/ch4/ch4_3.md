
# 权衡偏差和方差

截止当前的讨论中，我们都假设基函数的形式和数量都已给定。我们之前用于决定模型参数的极大自然估计，是一个非常贪心的方法。这与数据集的采样选取关系很大，很容易造成过拟合。 另一方面，基函数选取过多、过少；正则项权重过小、过大都容易引起过拟合/欠拟合的问题。我们需要有一个方法让我们选择一个合适的超参数，以平衡二者带来的好处和坏处。

从频率学家的角度来看，我们可以对模型性能做出**偏差-方差分解**。回忆在上一节中，我们尝试对决策的平方损失函数做形如下面这样的分解
$$
\begin{align*}
\mathbb{E}[L] 
&= \int (f(\boldsymbol{x}) - h(\boldsymbol{x}))^{2}  p(\boldsymbol{x}) \,\mathrm{d}\boldsymbol{x} + \iint (h(\boldsymbol{x}) - t)^{2} p(\boldsymbol{x}, t) \, \mathrm d{\boldsymbol{x}} \,\mathrm{d}t
\end{align*}
$$
可见第二项与 $f$ 的选取无关，它的值是我们取 $f$ 所能使得 $\mathbb{E}[L]$ 达到的最小值，也就是使得前一项为零。但这是在我们能拿到无限数据的情况下的理想结果：在前面的内容中，对于平方损失，我们的结果是 $h(\boldsymbol{x}) = \mathbb{E}_{t}[t|\boldsymbol{x}]$，而只有样本趋于无穷大时，样本均值才会趋于这个期望值。换句话说，在实际情况下，也即数据集中的数据量有限时，我们无法得知准确的 $h$ 。

假如我们使用一个参数 $\boldsymbol{w}$ 建模 $h$，频率学派会通过点估计来描述该模型对于不确定的训练数据集下的性能：假设我们得到的数据来源于一个分布 $p(t, \boldsymbol{x})$。这样的话我们每“生成”一个训练集 $\mathcal{D}$，都可以跑之前的函数，然后得到一个该数据集对应的决策函数 $f(\boldsymbol{x}; \mathcal{D})$。此时我们就可以考虑决策函数与 $h$ 之差的平方关于 $\mathcal{D}$ 的期望

$$
\begin{align*}
\mathbb{E}_{\mathcal{D}}\Big[\big\{ f(\boldsymbol{x}; \mathcal{D}) - h(\boldsymbol{x}) \big\}^{2}\Big] &= \mathbb{E}_{\mathcal{D}}\Big[\big\{f(\boldsymbol{x}; \mathcal{D}) - \mathbb{E}_{\mathcal{D}}[f(\boldsymbol{x}; \mathcal{D})] + \mathbb{E}_{\mathcal{D}}[f(\boldsymbol{x}; \mathcal{D})] - h(\boldsymbol{x}) \big\}^{2}\Big]\\
&= \mathbb{E}_{\mathcal{D}}\Big[\big\{ f(\boldsymbol{x}; \mathcal{D}) - \mathbb{E}_{\mathcal{D}}[f(\boldsymbol{x}; \mathcal{D})]\big\}^{2}\Big] \\&\quad \quad  + \mathbb{E}_{\mathcal{D}}\Big[\big\{ f(\boldsymbol{x}; \mathcal{D}) - \mathbb{E}_{\mathcal{D}}[f(\boldsymbol{x}; \mathcal{D})]\big\}\big\{ \mathbb{E}_{\mathcal{D}}[f(\boldsymbol{x}; \mathcal{D})] - h(\boldsymbol{x}) \big\} \Big]\\&\quad \quad  + \mathbb{E}_{\mathcal{D}}\Big[\big\{\mathbb{E}_{\mathcal{D}}[f(\boldsymbol{x}; \mathcal{D})] - h(\boldsymbol{x}) \big\}^{2}\Big]\\
&= \mathbb{E}_{\mathcal{D}}\Big[\big\{ f(\boldsymbol{x}; \mathcal{D}) - \mathbb{E}_{\mathcal{D}}[f(\boldsymbol{x}; \mathcal{D})]\big\}^{2}\Big] \\&\quad \quad  + \big\{ \mathbb{E}_{\mathcal{D}}[f(\boldsymbol{x}; \mathcal{D})] - h(\boldsymbol{x}) \big\}  \cdot \underbrace{ \mathbb{E}_{\mathcal{D}}\Big[\big\{ f(\boldsymbol{x}; \mathcal{D}) - \mathbb{E}_{\mathcal{D}}[f(\boldsymbol{x}; \mathcal{D})]\big\}\Big] }_{ 0 }\\&\quad \quad  + \mathbb{E}_{\mathcal{D}}\Big[\big\{\mathbb{E}_{\mathcal{D}}[f(\boldsymbol{x}; \mathcal{D})] - h(\boldsymbol{x}) \big\}^{2}\Big]\\
&= \underbrace{ \big\{\mathbb{E}_{\mathcal{D}}[f(\boldsymbol{x}; \mathcal{D})] - h(\boldsymbol{x}) \big\}^{2} }_{ 偏差^{2} } + \underbrace{ \mathbb{E}_{\mathcal{D}}\Big[ \big\{ f(\boldsymbol{x}; \mathcal{D}) - \mathbb{E}_{\mathcal{D}}[f(\boldsymbol{x}; \mathcal{D})]\big\}^{2} \Big] }_{ 方差 }
\end{align*}
$$

可以看到，第一项括号里面是不同数据集对应函数的期望与 $h$ 之差的平方，我们称之为**偏差平方**，第二项括号中写的是单次采样数据集对应的决策函数与决策函数对数据集的期望之差平方（的期望），这其实就是 $f$ 的**方差**。我们把这个结果用回对平方损失函数的分析。我们考虑平方损失函数对数据集的期望：

$$
\begin{align*}
\mathbb{E}_{\mathcal{D}}[\mathbb{E}_{\boldsymbol{x}, t}[L]] 
&= \mathbb{E}_{\mathcal{D}}\left[ \int (f(\boldsymbol{x}) - h(\boldsymbol{x}))^{2}  p(\boldsymbol{x}) \,\mathrm{d}\boldsymbol{x} \right] + \mathbb{E}_{\mathcal{D}}\left[\iint (h(\boldsymbol{x}) - t)^{2} p(\boldsymbol{x}, t) \, \mathrm d{\boldsymbol{x}} \,\mathrm{d}t\right]\\
&= \int {\color{red} \mathbb{E}_{\mathcal{D}}\left[ (f(\boldsymbol{x}) - h(\boldsymbol{x}))^{2}\right]  }   p(\boldsymbol{x}) \,\mathrm{d}\boldsymbol{x} + \iint (h(\boldsymbol{x}) - t)^{2} p(\boldsymbol{x}, t) \, \mathrm d{\boldsymbol{x}} \,\mathrm{d}t\\
&= \int \big\{\mathbb{E}_{\mathcal{D}}[f(\boldsymbol{x}; \mathcal{D})] - h(\boldsymbol{x}) \big\}^{2}    p(\boldsymbol{x}) \,\mathrm{d}\boldsymbol{x} &偏差^{2}\\&\quad \quad + \int \mathbb{E}_{\mathcal{D}}\Big[ \big\{ f(\boldsymbol{x}; \mathcal{D}) - \mathbb{E}_{\mathcal{D}}[f(\boldsymbol{x}; \mathcal{D})]\big\}^{2} \Big]  p(\boldsymbol{x}) \,\mathrm{d}\boldsymbol{x} & 方差\\&\quad \quad + \iint (h(\boldsymbol{x}) - t)^{2} p(\boldsymbol{x}, t) \, \mathrm d{\boldsymbol{x}} \,\mathrm{d}t& 噪声\\
\end{align*}
$$

这样一来我们就把原来的期望损失分成了有意义的三项之和。我们要最小化期望损失，就要最小化这三项。首先我们看见第三项和数据集和决策函数的选择无关，我们没法优化这一项。接着我们看前两项，会发现我们为了一项变得更小，会牺牲另一项：采用更加灵活的函数能降低偏差，但其对数据集选取的敏感度提升；我们也可以选择更加简单的函数，它们对数据集敏感度不高，但代价是拟合效果更差。

![](https://files.mdnice.com/user/55419/dc2eb4e2-29a0-490e-ac95-7dd13911e0f4.png)

这样的偏差与方差的权衡在我们使用正则化技巧是也会出现。图中是不同超参数下对正弦函数数据集的拟合情况。我们有100个这样的数据集（只画出20个）， 每个数据集中有25个数据点，我们使用的模型有24个Gauss基函数（总共25个参数，加上偏置项 $w_{0}$）。我们采用不同的正则化系数 $\lambda$，从上至下依次减小。左侧画出了所有20次的拟合结果，右侧画出了这些拟合结果的平均值。可以看到越小的 $\lambda$ 对应越大的方差，越小的偏差；而越大的 $\lambda$ 则预示着越小的方差和越大的偏差。假如我们把偏差、方差和测试的误差关于 $\ln\lambda$ 的曲线画在同一张图里面，那么它会像是下面这样

![](https://files.mdnice.com/user/55419/37e7d0f4-2a3f-4e25-a370-0b0d4e23d614.png)

贝叶斯学派对此有不同的视角：模型的不确定性可以被表达为 $\boldsymbol{w}$ 的后验分布。相关内容在 Bishop 的著作 Pattern Recognition and Machine Learning 中有描述，相关内容后续将会补充。

PS. 我开始查 PRML 的时候发现这章中大部分就是从那里原封不动搬过来的，可能作者觉得 Baysian 的版本太过冗长，在 PRML 中已经是独立的一章，考虑到现在 DL 兴起，就没把它再拿过来。不过笔者依然认为，Bayes视角下的回归问题肯定也是很精彩的。我偷了个懒，这篇写的比较短，附一张今天在IFC观景台拍的维港作为补偿


![f2891151e0437e2de0293d252a904e7](https://files.mdnice.com/user/55419/73b11186-187c-4471-9b1b-7933545eafba.jpg)



